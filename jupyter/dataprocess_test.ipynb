{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\r\n",
       "import org.apache.spark.sql.DataFrame\r\n",
       "import org.apache.spark.sql.functions\r\n",
       "import org.apache.spark.ml.feature.StringIndexer\r\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\r\n",
       "import org.apache.spark.ml.feature.Imputer\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n",
    "import org.apache.spark.sql.{DataFrame}\n",
    "import org.apache.spark.sql.functions\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.ml.{Pipeline,PipelineModel}\n",
    "import org.apache.spark.ml.feature.Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7909e424\r\n",
       "sc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@12b9fdb8\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder()\n",
    "    .appName(\"Utils\")\n",
    "    .master(\"local[2]\")\n",
    "    .getOrCreate()\n",
    "\n",
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [PassengerId: string, Survived: string ... 10 more fields]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"header\",true).load(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+--------+\n",
      "|Survived|   Sex|passengers_cnt|mean_age|\n",
      "+--------+------+--------------+--------+\n",
      "|       1|  male|            45|    36.0|\n",
      "|       1|female|            91|    35.0|\n",
      "|       0|female|             3|    26.0|\n",
      "|       0|  male|            77|    45.0|\n",
      "+--------+------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Pclass\")===1).groupBy(\"Survived\",\"Sex\").agg(functions.count(\"PassengerId\").alias(\"passengers_cnt\"),\n",
    "                                                            functions.round(functions.mean(\"Age\")).alias(\"mean_age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "udf: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,Some(List(StringType)))\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val udf = functions.udf { (x:String) => if(x==\"male\") 1 else 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_df: org.apache.spark.sql.DataFrame = [PassengerId: string, Survived: string ... 10 more fields]\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val new_df = df.withColumn(\"sex\",udf(df(\"Sex\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+---+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+---+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  1|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|  0|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|  0|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|  0|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  1|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  1|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  1|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  1|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|  0|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|  0|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|  0|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|  0|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  1|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  1|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|  0|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|  0|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  1|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  1|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|  0|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|  0|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+---+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features: Array[String] = Array(Survived, Pclass, sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked)\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var features = new_df.columns.filterNot(_.contains(\"Name\")).filterNot(_.contains(\"PassengerId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder: Array[org.apache.spark.ml.feature.StringIndexer] = Array(strIdx_127d34ff522f, strIdx_3e90cad96d88, strIdx_71fe82e0deae)\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val encoder = Array(\"Ticket\",\"Cabin\",\"Embarked\").flatMap{name=>\n",
    "    val indexer = new StringIndexer().setInputCol(name).setOutputCol(name+\"_encode\").setHandleInvalid(\"keep\")\n",
    "    Array(indexer)\n",
    "}.toArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipline: org.apache.spark.ml.Pipeline = pipeline_3c2fc629bd1f\r\n",
       "indexModel: org.apache.spark.ml.PipelineModel = pipeline_3c2fc629bd1f\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipline = new Pipeline().setStages(encoder)\n",
    "val indexModel = pipline.fit(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureDF: org.apache.spark.sql.DataFrame = [PassengerId: string, Survived: string ... 13 more fields]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureDF = indexModel.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+----+-----+-----+-------+-------------+------------+---------------+\n",
      "|Survived|Pclass|sex| Age|SibSp|Parch|   Fare|Ticket_encode|Cabin_encode|Embarked_encode|\n",
      "+--------+------+---+----+-----+-----+-------+-------------+------------+---------------+\n",
      "|       0|     3|  1|  22|    1|    0|   7.25|        257.0|       147.0|            0.0|\n",
      "|       1|     1|  0|  38|    1|    0|71.2833|        608.0|        87.0|            1.0|\n",
      "|       1|     3|  0|  26|    0|    0|  7.925|        292.0|       147.0|            0.0|\n",
      "|       1|     1|  0|  35|    1|    0|   53.1|         46.0|        42.0|            0.0|\n",
      "|       0|     3|  1|  35|    0|    0|   8.05|        425.0|       147.0|            0.0|\n",
      "|       0|     3|  1|null|    0|    0| 8.4583|        269.0|       147.0|            2.0|\n",
      "|       0|     1|  1|  54|    0|    0|51.8625|        438.0|       102.0|            0.0|\n",
      "|       0|     3|  1|   2|    3|    1| 21.075|         12.0|       147.0|            0.0|\n",
      "|       1|     3|  0|  27|    0|    2|11.1333|         27.0|       147.0|            0.0|\n",
      "|       1|     2|  0|  14|    1|    0|30.0708|         55.0|       147.0|            1.0|\n",
      "|       1|     3|  0|   4|    1|    1|   16.7|         65.0|         2.0|            0.0|\n",
      "|       1|     1|  0|  58|    0|    0|  26.55|        510.0|        72.0|            0.0|\n",
      "|       0|     3|  1|  20|    0|    0|   8.05|        658.0|       147.0|            0.0|\n",
      "|       0|     3|  1|  39|    1|    5| 31.275|          0.0|       147.0|            0.0|\n",
      "|       0|     3|  0|  14|    0|    0| 7.8542|        635.0|       147.0|            0.0|\n",
      "|       1|     2|  0|  55|    0|    0|     16|        336.0|       147.0|            0.0|\n",
      "|       0|     3|  1|   2|    4|    1| 29.125|          6.0|       147.0|            2.0|\n",
      "|       1|     2|  1|null|    0|    0|     13|        340.0|       147.0|            0.0|\n",
      "|       0|     3|  0|  31|    1|    0|     18|        254.0|       147.0|            0.0|\n",
      "|       1|     3|  0|null|    0|    0|  7.225|        441.0|       147.0|            1.0|\n",
      "+--------+------+---+----+-----+-----+-------+-------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "featureDF2: org.apache.spark.sql.DataFrame = [Survived: string, Pclass: string ... 8 more fields]\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureDF2 = featureDF.drop(Array(\"Ticket\",\"Cabin\",\"Embarked\",\"Name\",\"PassengerId\"):_*)\n",
    "featureDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "castDF: org.apache.spark.sql.DataFrame = [Survived: double, Pclass: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val castDF = featureDF2.select(featureDF2.columns.map{\n",
    "        colname=>col(colname).cast(\"double\").alias(colname)\n",
    "    \n",
    "}:_*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: double (nullable = true)\n",
      " |-- sex: double (nullable = false)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: double (nullable = true)\n",
      " |-- Parch: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Ticket_encode: double (nullable = false)\n",
      " |-- Cabin_encode: double (nullable = false)\n",
      " |-- Embarked_encode: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "castDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imputer: org.apache.spark.ml.feature.ImputerModel = imputer_838bf992fd26\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val imputer = new Imputer()\n",
    ".setInputCols(featureDF2.columns.takeRight(9))\n",
    ".setOutputCols(featureDF2.columns.takeRight(9).map{ name=> name+\"_inputed\"})\n",
    ".fit(castDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-------------+---------------------+------------+-------------+-----------------------+-----------+--------------+--------------------+\n",
      "|Survived|      Age_inputed|SibSp_inputed|Ticket_encode_inputed|Fare_inputed|Parch_inputed|Embarked_encode_inputed|sex_inputed|Pclass_inputed|Cabin_encode_inputed|\n",
      "+--------+-----------------+-------------+---------------------+------------+-------------+-----------------------+-----------+--------------+--------------------+\n",
      "|     0.0|             22.0|          1.0|                257.0|        7.25|          0.0|                    0.0|        1.0|           3.0|               147.0|\n",
      "|     1.0|             38.0|          1.0|                608.0|     71.2833|          0.0|                    1.0|        0.0|           1.0|                87.0|\n",
      "|     1.0|             26.0|          0.0|                292.0|       7.925|          0.0|                    0.0|        0.0|           3.0|               147.0|\n",
      "|     1.0|             35.0|          1.0|                 46.0|        53.1|          0.0|                    0.0|        0.0|           1.0|                42.0|\n",
      "|     0.0|             35.0|          0.0|                425.0|        8.05|          0.0|                    0.0|        1.0|           3.0|               147.0|\n",
      "|     0.0|29.69911764705882|          0.0|                269.0|      8.4583|          0.0|                    2.0|        1.0|           3.0|               147.0|\n",
      "|     0.0|             54.0|          0.0|                438.0|     51.8625|          0.0|                    0.0|        1.0|           1.0|               102.0|\n",
      "|     0.0|              2.0|          3.0|                 12.0|      21.075|          1.0|                    0.0|        1.0|           3.0|               147.0|\n",
      "|     1.0|             27.0|          0.0|                 27.0|     11.1333|          2.0|                    0.0|        0.0|           3.0|               147.0|\n",
      "|     1.0|             14.0|          1.0|                 55.0|     30.0708|          0.0|                    1.0|        0.0|           2.0|               147.0|\n",
      "|     1.0|              4.0|          1.0|                 65.0|        16.7|          1.0|                    0.0|        0.0|           3.0|                 2.0|\n",
      "|     1.0|             58.0|          0.0|                510.0|       26.55|          0.0|                    0.0|        0.0|           1.0|                72.0|\n",
      "|     0.0|             20.0|          0.0|                658.0|        8.05|          0.0|                    0.0|        1.0|           3.0|               147.0|\n",
      "|     0.0|             39.0|          1.0|                  0.0|      31.275|          5.0|                    0.0|        1.0|           3.0|               147.0|\n",
      "|     0.0|             14.0|          0.0|                635.0|      7.8542|          0.0|                    0.0|        0.0|           3.0|               147.0|\n",
      "|     1.0|             55.0|          0.0|                336.0|        16.0|          0.0|                    0.0|        0.0|           2.0|               147.0|\n",
      "|     0.0|              2.0|          4.0|                  6.0|      29.125|          1.0|                    2.0|        1.0|           3.0|               147.0|\n",
      "|     1.0|29.69911764705882|          0.0|                340.0|        13.0|          0.0|                    0.0|        1.0|           2.0|               147.0|\n",
      "|     0.0|             31.0|          1.0|                254.0|        18.0|          0.0|                    0.0|        0.0|           3.0|               147.0|\n",
      "|     1.0|29.69911764705882|          0.0|                441.0|       7.225|          0.0|                    1.0|        0.0|           3.0|               147.0|\n",
      "+--------+-----------------+-------------+---------------------+------------+-------------+-----------------------+-----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "imputedDF: org.apache.spark.sql.DataFrame = [Survived: double, Age_inputed: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val imputedDF = imputer.transform(castDF).drop(imputer.getInputCols:_*)\n",
    "imputedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
